{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a003be7",
   "metadata": {},
   "source": [
    "# Легкий способ парсинга новостных статей на Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24f2cd",
   "metadata": {},
   "source": [
    "В современном цифровом мире нас засыпают бесконечным потоком информации.\n",
    "Мы постоянно прокручиваем социальные сети и 24 часа в сутки имеем доступ к новостным каналам.\n",
    "Таким образом, существует множество новостей, которые нам надо знать и мы должны быть в состоянии их все быстро переварить.\n",
    "\n",
    "Итак, давайте разберем упражнение по сжатию новостных статей до размера, более удобного для их восприятия.\n",
    "\n",
    "Мы спарсим примерную статью, используя библиотеки request и BeautifulSoup, а затем сформируем ее краткое изложение при помощи великолепной библиотеки gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93818d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fab34be47a45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\corpora\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[1;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_blas_funcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlapack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    483\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 485\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_mstats_basic\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_continuous_distns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                                     _check_shape, _ShapeInfo)\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_boost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m from ._biasedurn import (_PyFishersNCHypergeometric,\n\u001b[0m\u001b[0;32m     21\u001b[0m                         \u001b[0m_PyWalleniusNCHypergeometric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                         _PyStochasticLib3)\n",
      "\u001b[1;32mscipy\\stats\\_biasedurn.pyx\u001b[0m in \u001b[0;36minit scipy.stats._biasedurn\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbit_generator.pyx\u001b[0m in \u001b[0;36minit numpy.random.bit_generator\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "# Pandas & Numpy\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9e3505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Отказано в доступе: 'C:\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n"
     ]
    }
   ],
   "source": [
    "# MISTAKE !!!!\n",
    "# ModuleNotFoundError: No module named 'numpy.random.bit_generator'\n",
    "\n",
    "# Запуск следующей строки заставил переустановить numpyпакет.\n",
    "# Поскольку пакет был каким-то образом поврежден, это было исправлено.\n",
    "# conda install numpy --force-reinstall\n",
    "\n",
    "# Или можно попробовать так:\n",
    "# pip3 install scipy==1.7.1 numpy==1.18.5 scikit-learn==0.24.2 --no-cache-dir --no-binary :all:\n",
    "\n",
    "!pip install numpy --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7050bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотеки для более удобного для их восприятия текстовых документов и статей\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fb298",
   "metadata": {},
   "source": [
    "#### Статья по которой воспроизводится данный урок лежит по ссылке:\n",
    "\n",
    "https://pythonist.ru/legkij-sposob-parsinga-novostnyh-statej-na-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fecd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выберем интересную статью:\n",
    "# Получаем текст страницы\n",
    "url = 'https://www.npr.org/2019/07/10/740387601/university-of-texas-austin-promises-free-tuition-for-low-income-students-in-2020'\n",
    "page = requests.get(url).text\n",
    "# print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ea9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3008502b",
   "metadata": {},
   "source": [
    "## Вебскрейпинг\n",
    "### Теперь приступим непосредственно к вебскрейпингу!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала мы превратим содержимое страницы в объект BeautifulSoup, что позволит нам анализировать HTML-теги.\n",
    "# Turn page into BeautifulSoup object to access HTML tags\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cff77",
   "metadata": {},
   "source": [
    "Затем нам нужно выяснить, какие HTML-теги содержат заголовок и основной текст статьи.\n",
    "В качестве отличного учебника по HTML можно использовать сайт HTML.com.\n",
    "\n",
    "[python_ad_block]\n",
    "Чтобы это сделать, мы будем использовать инструменты разработчика Google Chrome.\n",
    "Откроем статью в новой вкладке, кликнем по ней правой кнопкой мыши и в выпавшем меню выберем пункт Inspect (Просмотр кода).\n",
    "Это вызовет DevTools (инструменты разработчика) в панели справа:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899ff2d",
   "metadata": {},
   "source": [
    "Чтобы найти все HTML-теги, соответствующие всему, что вы видите на странице, нажмите на небольшую кнопочку наверху.\n",
    "На картинке она отмечена синей стрелкой.\n",
    "\n",
    "Теперь наводим указатель мыши на фрагмент страницы, который мы хотим исследовать.\n",
    "В данном случае это заголовок и основной текст статьи. И мы видим, какие теги отвечают за формат данного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заголовок статьи окружен c двух сторон тегом <h1>. Загрузим этот фрагмент следующим образом:\n",
    "\n",
    "# Get headline\n",
    "headline = soup.find('h1').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной текст статьи окружен тегами <p>. На этот раз нам нужно будет найти все такие теги,\n",
    "# содержащиеся на странице, поскольку в них заключен каждый абзац статьи.\n",
    "\n",
    "# Get text from all <p> tags.\n",
    "p_tags = soup.find_all('p’)\n",
    "# Get the text from each of the “p” tags and strip surrounding whitespace.\n",
    "p_tags_text = [tag.get_text().strip() for tag in p_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee42db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "470d82b5",
   "metadata": {},
   "source": [
    "Если вы изучите текст, который мы сохранили в переменную p_tags_text, то заметите, что есть некоторые фрагменты текста, не относящиеся к основной статье, например имя автора и некоторые подписи к изображениям.\n",
    "Они также заключены в теги <p>, поэтому и оказались здесь.\n",
    "Чтобы очистить этот текст от фрагментов, которые не являются частью основной статьи, мы в качестве фильтров используем несколько представлений списков.\n",
    "\n",
    "В этой статье подписи к изображениям содержат символ новой строки \\n.\n",
    "Поскольку мы знаем, что в настоящих предложениях в статье не бывает случайных переносов строк, мы можем смело отказаться от таких фрагментов.\n",
    "Точно так же мы можем отбрасывать фрагменты текста, не содержащие точки, поскольку мы знаем, что любое правильное предложение в статье будет содержать точку.\n",
    "Так мы сможем отбросить имя автора и некоторые другие ненужные нам вещи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b38aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Filter out sentences that contain newline characters '\\n' or don't contain periods.\n",
    "sentence_list = [sentence for sentence in p_tags_text if not '\\n' in sentence]\n",
    "sentence_list = [sentence for sentence in sentence_list if '.' in sentence]\n",
    "# Combine list items into string.\n",
    "article = ' '.join(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7cb9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c066cf07",
   "metadata": {},
   "source": [
    "## Резюме статьи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bedd16",
   "metadata": {},
   "source": [
    "Теперь, имея полный текст статьи, мы хотим получить его резюме (краткий пересказ содержания статьи).\n",
    "\n",
    "Gensim — отличный пакет Python для большого количества задач нейролингвистического программирования (НЛП).\n",
    "Он включает в себя довольно надежную функцию резюмирования, которой достаточно легко пользоваться.\n",
    "Она реализует разновидность алгоритма TextRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2eea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для использования этой функции нам нужна лишь одна строчка кода:\n",
    "\n",
    "summary = summarize(article_text, ratio=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790191fd",
   "metadata": {},
   "source": [
    "## Вот и все, мы сделали, что хотели!\n",
    "\n",
    "### Мы извлекли заголовок статьи и получили краткое изложение ее содержания.\n",
    "\n",
    "#### Теперь вы можете понять суть статьи примерно в три раза быстрее и сэкономить время для других дел. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e407ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4a6de",
   "metadata": {},
   "source": [
    "# Скрейпинг сайтов с помощью библиотек Beautifulsoup и Requests на Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb983fe7",
   "metadata": {},
   "source": [
    "### Делаем совместно с каналом \"Важные Истории\" на YouTube и его ведущей Алесей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=0ws5tsRBgL8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e23fd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека PYTHON для извлечения данных из файлов HTML и XML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Подключаем библиотеку для парсинга сайтов !!!!!!!!!!!!!\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b78fdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переменная со ссылкой на сайт\n",
    "# url = 'https://www.kinopoisk.ru/lists/movies/top250/'\n",
    "\n",
    "url = 'https://www.kinopoisk.ru/lists/categories/movies/1/'\n",
    "# https://www.kinopoisk.ru/lists/movies/top250/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eef5cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём запрос\n",
    "response = requests.get(url)\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc4308e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body></body><script nonce=\"9ea8db73cbda0fdae8857745c46f37cf\">var it = {\"host\":\"https:\\u002F\\u002Fsso.kinopoisk.ru\\u002Finstall?uuid=7c2d03d6-4a04-4dea-bd95-d646825e7a5c\",\"retpath\":\"https:\\u002F\\u002Fwww.kinopoisk.ru\\u002Flists\\u002Fcategories\\u002Fmovies\\u002F1\\u002F\"};(function() { var form = document.createElement('form'); var element1 = document.createElement('input'); var element2 = document.createElement('input'); element1.name = 'retpath'; element1.type = 'hidden'; element1.value = it.retpath; form.appendChild(element1); element2.name = 'container'; element2.type = 'hidden'; element2.value = '1732034935.10150276.79Iw7_Jy9u7S-9yV.6W04ceONJ4nImUYKqkqzI7h3fSiUczhG9dp9Ybjt4HcF3z6pPvYKv8pETZOVx-fngz0XJqLmOEDsYx_P5fJAwy2jLQ39oLovuIXc1f2r_sOQ5WgZHm36k-CJ0HHXmAHryWZDhyLBrW5kHLN-mGG1H4vv4ZVJRCcLOzo7QocXqKSPblLQt9QvT1hM21ieZ2NsS7QSM5gUJo7AEwfaI91CrXxpwtNlAhNfOhLXMdtLRAHA2NivGOibMRAZL69wCwKHRba1ksfD5d6ehQlLAL_kpLhuC9A-GZzasFL62EuIxOp2dBoKClN0pnsuaLz9CrFjh0Oo_eh2spqZHeHgYKzxAOY6lpkSoicFGELQ8colQlR8xpUs395cQgj6Kv4fcCwRiQUuOftr4gvfawy0hvBSmFtXwd5ETHB-srvJ5Kn6GdAaGhHcl9TuvgSNXMSt_yt6bDtmWzqQleyl375p2GDGsC2836V3SY5DwCBSQDpkv30_seD7WC7jRR_AFr467v1ojcO2UhEip74ZdPcLx6xR_sQ3qP0IeCPsHRvLmEW7671gGo05yKbBzsKYzVs7EMcqpHBrilyQrvFmZ8_Ez3HzmEa0Q88flxHTlbvp7-RA2J9ZBJf9aL6TkkP1bnyYryrWPBGr5LPchC9eFv9hUPtfrA9kgiIS0n99hr1GW4e86P3Q0KWjClaVfa5gQjPmBwCOwS2PJUraszSsb_LloleUCuRQq_P73Q2wkeiSIQt2-f0hCnV1GxN04LtbfowojsLHkIvyk7krxQKbQFIM6LC17GWGLQ_dzHLAqBPeRgpKhhawnpqfBBtmnGV61Mytf4tK6xr5WO-gHbZjO5s6XUalx3QbCL3L4KYmhCOvRfR5zZJ9TkYZyjqSvx3WmNWcYNRvOqCnQrP4drOKvFdefmmHgKlOniGlVcqMLH7ZvTdXLLRdfHJqjWn_ioU6pY6KPuY_hqZd2wFL9e4L4Mqq_Qb6yNyzHLNskMxlXSICiPOAepfGuVlMOJmt1In7Q7X1ReyUjwPOChm0Z86BsY8mw8Ory010KtWP8yh0KxlxiLpQT62-5vn2fiQ-9TJWuzMk-lFZLqr_XuVjvSZMC_ztCLeDxE4xZrUUSjU47MxDBHTjSXYhU805AEWD73a6pX8j7LRkzpyJ0uC91HrON9dW53s9i8GW4ac2Bxbl1CIjjHleY_dsvSCXs2evu7Lwvs91dETgp-E_wck6fmlJpHXInpLAWht-C9UgMg.xM_k_Xi0CJx_7ByS3zvlkA'; form.appendChild(element2); form.method = 'POST'; form.action = it.host; document.body.appendChild(form); form.submit();})();</script></html>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объект SOUP\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15b8f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Определяем DIV-ы с нужной инфой (заголовки статей)\n",
    "# film = soup.find('div', class_ = 'styles_root__ti07r')\n",
    "film = soup.find('div', class_ = 'styles_meta__M_kDW')\n",
    "print(film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3830036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd6f8383",
   "metadata": {},
   "source": [
    "# Простой парсинг сайтов на Python | requests, BeautifulSoup, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239016b2",
   "metadata": {},
   "source": [
    "### Делаем совместно с каналом Андрея Андриевского"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdee21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека PYTHON для извлечения данных из файлов HTML и XML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Подключаем библиотеку для парсинга сайтов !!!!!!!!!!!!!\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём переменные-КОНСТАНТЫ\n",
    "# HOST = 'https://www.kinopoisk.ru/'\n",
    "# URL = 'https://www.kinopoisk.ru/lists/movies/top250/'\n",
    "# HEADERS = {\n",
    "#     'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "#     'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f56d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём переменные-КОНСТАНТЫ\n",
    "HOST = 'https://vc.ru'\n",
    "URL = 'https://vc.ru/popular'\n",
    "HEADERS = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "}\n",
    "CSV = 'catalog.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b589f25",
   "metadata": {},
   "source": [
    "#### Парсинг осуществляется при помощи нескольких функции, вызываемых главной функцией (не ООП !!!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301fce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Функция - обращение к вебстранице для получения кода HTML:\n",
    "def get_html(url, params=''):\n",
    "    r = requests.get(url, headers=HEADERS, params=params)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac1afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "result = get_html(URL)\n",
    "print(result)\n",
    "\n",
    "# <Response [200]> - это значит, что ошибки нет и в переменной содержится код страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94f1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Функция, которая будет получать нужную для наших задач информацию \n",
    "def get_content(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "#     soup = BeautifulSoup(html, 'lxml')\n",
    "    articles = soup.find_all('div', class_ = 'content content--short')\n",
    "    catalog = []\n",
    "#     print(item)\n",
    "    \n",
    "    for article in articles:\n",
    "        catalog.append({\n",
    "            'title': article.find('div', class_ = 'content-title').get_text(),\n",
    "            'text': article.find('div', class_ = 'block-text').get_text(),\n",
    "            'link': HOST + article.find('a', class_ = 'content__link')['href']\n",
    "        })\n",
    "        \n",
    "    return catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eecc977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'На вас тайно зарабатывают, а вы и не знали. Кто и как зарабатывает миллионы на обычных пользователях соц.сетей? ',\n",
       "  'text': 'Всем известно, что на нас зарабатывают абсолютно везде: от нашего рождения до наших похорон. Но как им удается тайно зарабатывать на нас даже во время обычного скроллинга соц.сетей? Давайте разбираться!',\n",
       "  'link': 'https://vc.ru/marketing/1741934-na-vas-taino-zarabatyvayut-a-vy-i-ne-znali-kto-i-kak-zarabatyvaet-milliony-na-obychnyh-polzovatelyah-socsetei'},\n",
       " {'title': 'Как защитить свои тексты от ChatGPT и других ИИ-ботов. Вот почему вы должны это сделать, и я обещаю, что это не сложно и не страшно ',\n",
       "  'text': 'Большинство людей не осознают, какой огромный объем слов требуется для обучения ИИ-программ, таких как ChatGPT или Claude. Когда два года назад была запущена первая версия ChatGPT, она была обучена примерно на 300 миллиардах слов.',\n",
       "  'link': 'https://vc.ru/chatgpt/1742007-kak-zashitit-svoi-teksty-ot-chatgpt-i-drugih-ii-botov-vot-pochemu-vy-dolzhny-eto-sdelat-i-ya-obeshayu-chto-eto-ne-slozhno-i-ne-strashno'},\n",
       " {'title': 'Аномальный взлёт рынка акций завершился? Первый биржевой обзор в 2025 году! ',\n",
       "  'text': 'Мощный рост акций продолжился и в последний торговый день ушедшего года. Причем он не просто продолжился, а, скорее, даже ускорился! В понедельник с утра резко вырос индекс ММВБ аж на 2% буквально за 15 минут, хотя никаких новых позитивных новостей не появилось, как и в предыдущие дни роста. В итоге к концу дня индекс вырос на 3,46%, до 2883 пункто…',\n",
       "  'link': 'https://vc.ru/money/1737682-anomalnyi-vzlet-rynka-akcii-zavershilsya-pervyi-birzhevoi-obzor-v-2025-godu'},\n",
       " {'title': 'Как нанять крутого сотрудника и не разориться (реальный кейс) ',\n",
       "  'text': 'Часто мы предъявляем к соискателям длиннююююющие списки требований. Но действительно ли это эффективно? И сколько будет вам стоить такой супергерой?',\n",
       "  'link': 'https://vc.ru/life/1739694-kak-nanyat-krutogo-sotrudnika-i-ne-razoritsya-realnyi-keis'},\n",
       " {'title': 'Кейс: внедрение системы планирования найма ',\n",
       "  'text': 'Полтора года назад, когда я присоединилась к EdTech продукту со штатом сотрудников 150+ человек, передо мной стояла задача за короткий срок внедрить планирование системы найма и сделать так, чтобы бизнес перестал работать из позиции «пожарных» решений в рекрутменте.',\n",
       "  'link': 'https://vc.ru/life/1742011-keis-vnedrenie-sistemy-planirovaniya-naima'},\n",
       " {'title': 'День 1047: Китай впервые вошёл в тройку крупнейших поставщиков пива в Россию ',\n",
       "  'text': 'Собираем новости, события и мнения о рынках, банках и реакциях компаний.',\n",
       "  'link': 'https://vc.ru/money/1741346-den-1047-kitai-vpervye-voshel-v-troiku-krupneishih-postavshikov-piva-v-rossiyu'},\n",
       " {'title': 'Граффити как средство творчества и социальной коммуникации? ',\n",
       "  'text': 'Граффити вроде бы давно вышло за рамки простых надписей на стенах и сегодня в какой-то мере они становится формой искусства, способной передавать глубокие идеи, смыслы и эмоции. Художники используют городские пространства как свои холсты, создавая уникальные произведения, которые отражают их индивидуальность и взгляды на окружающий мир. Но так ли с…',\n",
       "  'link': 'https://vc.ru/opinions/1742000-graffiti-kak-sredstvo-tvorchestva-i-socialnoi-kommunikacii'},\n",
       " {'title': 'Какой контент создавать в 2025? ',\n",
       "  'text': 'Новогодние праздники – это для многих время отдыха и приостановки гонки за метриками в соцсетях. Но всё же чтобы увереннее войти в новый рабочий год, я подготовила для вас список трендов, которые мы с высокой вероятностью увидим в соцсетях в этом году. А значит, чтобы не оказаться на обочине «соушл мидиа» жизни, мы должны адаптировать свой контент…',\n",
       "  'link': 'https://vc.ru/marketing/1741651-kakoi-kontent-sozdavat-v-2025'},\n",
       " {'title': 'Чего действительно не хватает в Телеграм? ',\n",
       "  'text': 'На волне очередных ненужных ТГ-обновлений, которые давно вошли в разряд «прочитал и забыл», захотелось написать свой короткий wish-list:',\n",
       "  'link': 'https://vc.ru/social/1741463-chego-deistvitelno-ne-hvataet-v-telegram'},\n",
       " {'title': 'Как понять, какой товар перерасходует Ваши деньги? Способ за три клика. Бесплатный способ. ',\n",
       "  'text': 'Рассказываю о том, как проще найти товар который не выкупают и кушает Ваши деньги за логистику. ',\n",
       "  'link': 'https://vc.ru/marketplace/1741775-kak-ponyat-kakoi-tovar-pererashoduet-vashi-dengi-sposob-za-tri-klika-besplatnyi-sposob'},\n",
       " {'title': '10 ключевых ошибок при управлении строительными проектами и как их избежать ',\n",
       "  'text': 'Около 70% строительных проектов сталкиваются с превышением бюджета или сроков. Ваш — наверняка, не исключение… Главная причина — ошибки управления и отсутствие системного подхода.',\n",
       "  'link': 'https://vc.ru/u/3594612-artem-pro-stroitelnyi-biznes/1740503-10-klyuchevyh-oshibok-pri-upravlenii-stroitelnymi-proektami-i-kak-ih-izbezhat'},\n",
       " {'title': 'Онлайн-школа привлекла 2,3 млн ₽ через Telegram-бота с CPL 94 ₽. ',\n",
       "  'text': 'В этом случае мы успешно привлекли 7,2 тысячи клиентов с помощью автоматизированной воронки. Модерация бота заняла всего 4 дня, что значительно быстрее, чем обычно. В ручном режиме нашли эффективные каналы для продвижения и в результате окупили затраты на рекламу в 4 раза.',\n",
       "  'link': 'https://vc.ru/marketing/1733628-onlain-shkola-privlekla-23-mln-cherez-telegram-bota-s-cpl-94'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "content = get_content(result.text)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc98517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для записи результатов парсинга в файл\n",
    "def save_doc(articles, path):\n",
    "    with open(path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow(['TITLE', 'TEXT', 'LINK'])\n",
    "        for item in items:\n",
    "            writer.writerow([\n",
    "                item['title'],\n",
    "                item['text'],\n",
    "                item['link']\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a2e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обработки и запуска всех функций и определения количества страниц для парсинга:\n",
    "def parser():\n",
    "    PAGENATION =input('Сколько страниц вы хотите запарсить? ')\n",
    "    PAGENATION = int(PAGENATION.strip())\n",
    "    html = get_html(URL)\n",
    "    \n",
    "    if html.status == 200:\n",
    "        catalog = []\n",
    "        for page in range(1, PAGENATION):\n",
    "            print(f'Парсим страницу: {page}')\n",
    "            html = get_html(URL, params={'page': page})\n",
    "            catalog.extend(get_content(html.text))\n",
    "        print('PARSING ENDED')\n",
    "        print(catalog)\n",
    "        save_doc(catalog, CSV)\n",
    "    else:\n",
    "        print('ERROR !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a2498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Сколько страниц вы хотите запарсить?  2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Response' object has no attribute 'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mparser\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m PAGENATION \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(PAGENATION\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m      5\u001b[0m html \u001b[38;5;241m=\u001b[39m get_html(URL)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m      8\u001b[0m     catalog \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, PAGENATION):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Response' object has no attribute 'status'"
     ]
    }
   ],
   "source": [
    "## \n",
    "parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acba18d-e91a-4ab9-baad-9fa16c8e1cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
