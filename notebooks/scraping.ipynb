{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Легкий способ парсинга новостных статей на Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В современном цифровом мире нас засыпают бесконечным потоком информации.\n",
    "Мы постоянно прокручиваем социальные сети и 24 часа в сутки имеем доступ к новостным каналам.\n",
    "Таким образом, существует множество новостей, которые нам надо знать и мы должны быть в состоянии их все быстро переварить.\n",
    "\n",
    "Итак, давайте разберем упражнение по сжатию новостных статей до размера, более удобного для их восприятия.\n",
    "\n",
    "Мы спарсим примерную статью, используя библиотеки request и BeautifulSoup, а затем сформируем ее краткое изложение при помощи великолепной библиотеки gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fab34be47a45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\corpora\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[1;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\gensim\\matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_blas_funcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlapack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    483\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 485\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_mstats_basic\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_continuous_distns\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                                     _check_shape, _ShapeInfo)\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_boost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m from ._biasedurn import (_PyFishersNCHypergeometric,\n\u001b[0m\u001b[0;32m     21\u001b[0m                         \u001b[0m_PyWalleniusNCHypergeometric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                         _PyStochasticLib3)\n",
      "\u001b[1;32mscipy\\stats\\_biasedurn.pyx\u001b[0m in \u001b[0;36minit scipy.stats._biasedurn\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbit_generator.pyx\u001b[0m in \u001b[0;36minit numpy.random.bit_generator\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "# Pandas & Numpy\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Отказано в доступе: 'C:\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n"
     ]
    }
   ],
   "source": [
    "# MISTAKE !!!!\n",
    "# ModuleNotFoundError: No module named 'numpy.random.bit_generator'\n",
    "\n",
    "# Запуск следующей строки заставил переустановить numpyпакет.\n",
    "# Поскольку пакет был каким-то образом поврежден, это было исправлено.\n",
    "# conda install numpy --force-reinstall\n",
    "\n",
    "# Или можно попробовать так:\n",
    "# pip3 install scipy==1.7.1 numpy==1.18.5 scikit-learn==0.24.2 --no-cache-dir --no-binary :all:\n",
    "\n",
    "!pip install numpy --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотеки для более удобного для их восприятия текстовых документов и статей\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Статья по которой воспроизводится данный урок лежит по ссылке:\n",
    "\n",
    "https://pythonist.ru/legkij-sposob-parsinga-novostnyh-statej-na-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выберем интересную статью:\n",
    "# Получаем текст страницы\n",
    "url = 'https://www.npr.org/2019/07/10/740387601/university-of-texas-austin-promises-free-tuition-for-low-income-students-in-2020'\n",
    "page = requests.get(url).text\n",
    "# print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вебскрейпинг\n",
    "### Теперь приступим непосредственно к вебскрейпингу!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала мы превратим содержимое страницы в объект BeautifulSoup, что позволит нам анализировать HTML-теги.\n",
    "# Turn page into BeautifulSoup object to access HTML tags\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем нам нужно выяснить, какие HTML-теги содержат заголовок и основной текст статьи.\n",
    "В качестве отличного учебника по HTML можно использовать сайт HTML.com.\n",
    "\n",
    "[python_ad_block]\n",
    "Чтобы это сделать, мы будем использовать инструменты разработчика Google Chrome.\n",
    "Откроем статью в новой вкладке, кликнем по ней правой кнопкой мыши и в выпавшем меню выберем пункт Inspect (Просмотр кода).\n",
    "Это вызовет DevTools (инструменты разработчика) в панели справа:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы найти все HTML-теги, соответствующие всему, что вы видите на странице, нажмите на небольшую кнопочку наверху.\n",
    "На картинке она отмечена синей стрелкой.\n",
    "\n",
    "Теперь наводим указатель мыши на фрагмент страницы, который мы хотим исследовать.\n",
    "В данном случае это заголовок и основной текст статьи. И мы видим, какие теги отвечают за формат данного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заголовок статьи окружен c двух сторон тегом <h1>. Загрузим этот фрагмент следующим образом:\n",
    "\n",
    "# Get headline\n",
    "headline = soup.find('h1').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной текст статьи окружен тегами <p>. На этот раз нам нужно будет найти все такие теги,\n",
    "# содержащиеся на странице, поскольку в них заключен каждый абзац статьи.\n",
    "\n",
    "# Get text from all <p> tags.\n",
    "p_tags = soup.find_all('p’)\n",
    "# Get the text from each of the “p” tags and strip surrounding whitespace.\n",
    "p_tags_text = [tag.get_text().strip() for tag in p_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы изучите текст, который мы сохранили в переменную p_tags_text, то заметите, что есть некоторые фрагменты текста, не относящиеся к основной статье, например имя автора и некоторые подписи к изображениям.\n",
    "Они также заключены в теги <p>, поэтому и оказались здесь.\n",
    "Чтобы очистить этот текст от фрагментов, которые не являются частью основной статьи, мы в качестве фильтров используем несколько представлений списков.\n",
    "\n",
    "В этой статье подписи к изображениям содержат символ новой строки \\n.\n",
    "Поскольку мы знаем, что в настоящих предложениях в статье не бывает случайных переносов строк, мы можем смело отказаться от таких фрагментов.\n",
    "Точно так же мы можем отбрасывать фрагменты текста, не содержащие точки, поскольку мы знаем, что любое правильное предложение в статье будет содержать точку.\n",
    "Так мы сможем отбросить имя автора и некоторые другие ненужные нам вещи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Filter out sentences that contain newline characters '\\n' or don't contain periods.\n",
    "sentence_list = [sentence for sentence in p_tags_text if not '\\n' in sentence]\n",
    "sentence_list = [sentence for sentence in sentence_list if '.' in sentence]\n",
    "# Combine list items into string.\n",
    "article = ' '.join(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Резюме статьи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, имея полный текст статьи, мы хотим получить его резюме (краткий пересказ содержания статьи).\n",
    "\n",
    "Gensim — отличный пакет Python для большого количества задач нейролингвистического программирования (НЛП).\n",
    "Он включает в себя довольно надежную функцию резюмирования, которой достаточно легко пользоваться.\n",
    "Она реализует разновидность алгоритма TextRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для использования этой функции нам нужна лишь одна строчка кода:\n",
    "\n",
    "summary = summarize(article_text, ratio=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вот и все, мы сделали, что хотели!\n",
    "\n",
    "### Мы извлекли заголовок статьи и получили краткое изложение ее содержания.\n",
    "\n",
    "#### Теперь вы можете понять суть статьи примерно в три раза быстрее и сэкономить время для других дел. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Скрейпинг сайтов с помощью библиотек Beautifulsoup и Requests на Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем совместно с каналом \"Важные Истории\" на YouTube и его ведущей Алесей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=0ws5tsRBgL8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека PYTHON для извлечения данных из файлов HTML и XML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Подключаем библиотеку для парсинга сайтов !!!!!!!!!!!!!\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переменная со ссылкой на сайт\n",
    "# url = 'https://www.kinopoisk.ru/lists/movies/top250/'\n",
    "\n",
    "url = 'https://www.kinopoisk.ru/lists/categories/movies/1/'\n",
    "# https://www.kinopoisk.ru/lists/movies/top250/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём запрос\n",
    "response = requests.get(url)\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body></body><script nonce=\"9ea8db73cbda0fdae8857745c46f37cf\">var it = {\"host\":\"https:\\u002F\\u002Fsso.kinopoisk.ru\\u002Finstall?uuid=7c2d03d6-4a04-4dea-bd95-d646825e7a5c\",\"retpath\":\"https:\\u002F\\u002Fwww.kinopoisk.ru\\u002Flists\\u002Fcategories\\u002Fmovies\\u002F1\\u002F\"};(function() { var form = document.createElement('form'); var element1 = document.createElement('input'); var element2 = document.createElement('input'); element1.name = 'retpath'; element1.type = 'hidden'; element1.value = it.retpath; form.appendChild(element1); element2.name = 'container'; element2.type = 'hidden'; element2.value = '1732034935.10150276.79Iw7_Jy9u7S-9yV.6W04ceONJ4nImUYKqkqzI7h3fSiUczhG9dp9Ybjt4HcF3z6pPvYKv8pETZOVx-fngz0XJqLmOEDsYx_P5fJAwy2jLQ39oLovuIXc1f2r_sOQ5WgZHm36k-CJ0HHXmAHryWZDhyLBrW5kHLN-mGG1H4vv4ZVJRCcLOzo7QocXqKSPblLQt9QvT1hM21ieZ2NsS7QSM5gUJo7AEwfaI91CrXxpwtNlAhNfOhLXMdtLRAHA2NivGOibMRAZL69wCwKHRba1ksfD5d6ehQlLAL_kpLhuC9A-GZzasFL62EuIxOp2dBoKClN0pnsuaLz9CrFjh0Oo_eh2spqZHeHgYKzxAOY6lpkSoicFGELQ8colQlR8xpUs395cQgj6Kv4fcCwRiQUuOftr4gvfawy0hvBSmFtXwd5ETHB-srvJ5Kn6GdAaGhHcl9TuvgSNXMSt_yt6bDtmWzqQleyl375p2GDGsC2836V3SY5DwCBSQDpkv30_seD7WC7jRR_AFr467v1ojcO2UhEip74ZdPcLx6xR_sQ3qP0IeCPsHRvLmEW7671gGo05yKbBzsKYzVs7EMcqpHBrilyQrvFmZ8_Ez3HzmEa0Q88flxHTlbvp7-RA2J9ZBJf9aL6TkkP1bnyYryrWPBGr5LPchC9eFv9hUPtfrA9kgiIS0n99hr1GW4e86P3Q0KWjClaVfa5gQjPmBwCOwS2PJUraszSsb_LloleUCuRQq_P73Q2wkeiSIQt2-f0hCnV1GxN04LtbfowojsLHkIvyk7krxQKbQFIM6LC17GWGLQ_dzHLAqBPeRgpKhhawnpqfBBtmnGV61Mytf4tK6xr5WO-gHbZjO5s6XUalx3QbCL3L4KYmhCOvRfR5zZJ9TkYZyjqSvx3WmNWcYNRvOqCnQrP4drOKvFdefmmHgKlOniGlVcqMLH7ZvTdXLLRdfHJqjWn_ioU6pY6KPuY_hqZd2wFL9e4L4Mqq_Qb6yNyzHLNskMxlXSICiPOAepfGuVlMOJmt1In7Q7X1ReyUjwPOChm0Z86BsY8mw8Ory010KtWP8yh0KxlxiLpQT62-5vn2fiQ-9TJWuzMk-lFZLqr_XuVjvSZMC_ztCLeDxE4xZrUUSjU47MxDBHTjSXYhU805AEWD73a6pX8j7LRkzpyJ0uC91HrON9dW53s9i8GW4ac2Bxbl1CIjjHleY_dsvSCXs2evu7Lwvs91dETgp-E_wck6fmlJpHXInpLAWht-C9UgMg.xM_k_Xi0CJx_7ByS3zvlkA'; form.appendChild(element2); form.method = 'POST'; form.action = it.host; document.body.appendChild(form); form.submit();})();</script></html>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объект SOUP\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Определяем DIV-ы с нужной инфой (заголовки статей)\n",
    "# film = soup.find('div', class_ = 'styles_root__ti07r')\n",
    "film = soup.find('div', class_ = 'styles_meta__M_kDW')\n",
    "print(film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простой парсинг сайтов на Python | requests, BeautifulSoup, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем совместно с каналом Андрея Андриевского"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека PYTHON для извлечения данных из файлов HTML и XML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Подключаем библиотеку для парсинга сайтов !!!!!!!!!!!!!\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём переменные-КОНСТАНТЫ\n",
    "# HOST = 'https://www.kinopoisk.ru/'\n",
    "# URL = 'https://www.kinopoisk.ru/lists/movies/top250/'\n",
    "# HEADERS = {\n",
    "#     'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "#     'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём переменные-КОНСТАНТЫ\n",
    "HOST = 'https://vc.ru'\n",
    "URL = 'https://vc.ru/popular'\n",
    "HEADERS = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "}\n",
    "CSV = 'catalog.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Парсинг осуществляется при помощи нескольких функции, вызываемых главной функцией (не ООП !!!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Функция - обращение к вебстранице для получения кода HTML:\n",
    "def get_html(url, params=''):\n",
    "    r = requests.get(url, headers=HEADERS, params=params)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "result = get_html(URL)\n",
    "print(result)\n",
    "\n",
    "# <Response [200]> - это значит, что ошибки нет и в переменной содержится код страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Функция, которая будет получать нужную для наших задач информацию \n",
    "def get_content(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "#     soup = BeautifulSoup(html, 'lxml')\n",
    "    articles = soup.find_all('div', class_ = 'content content--short')\n",
    "    catalog = []\n",
    "#     print(item)\n",
    "    \n",
    "    for article in articles:\n",
    "        catalog.append({\n",
    "            'title': article.find('div', class_ = 'content-title').get_text(),\n",
    "            'text': article.find('div', class_ = 'block-text').get_text(),\n",
    "            'link': HOST + article.find('a', class_ = 'content__link')['href']\n",
    "        })\n",
    "        \n",
    "    return catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Официальный курс доллара превысил 100 рублей ',\n",
       "  'text': 'Курс на 20 ноября 2024 года — 100,03 рубля.',\n",
       "  'link': 'https://vc.ru/money/1662348-oficialnyi-kurs-dollara-prevysil-100-rublei'},\n",
       " {'title': 'Jaguar представил новый логотип — без ягуара в нём ',\n",
       "  'text': 'Но его изображение останется одним из элементов фирменного стиля.',\n",
       "  'link': 'https://vc.ru/design/1662196-jaguar-predstavil-novyi-logotip-bez-yaguara-v-nem'},\n",
       " {'title': 'Производитель «умных» колец Oura привлёк $75 млн при оценке в $5 млрд ',\n",
       "  'text': 'Оценка выросла в два раза с 2022 года. ',\n",
       "  'link': 'https://vc.ru/invest/1662441-proizvoditel-umnyh-kolec-oura-privlek-75-mln-pri-ocenke-v-5-mlrd'},\n",
       " {'title': '«Предприниматель должен уметь работать в любых условиях»: основатель «Красное & Белое» — об онлайн-продаже алкоголя, параллельном импорте и возможном IPO ',\n",
       "  'text': 'Тезисы из беседы Сергея Студенникова с РБК.',\n",
       "  'link': 'https://vc.ru/retail/1656031-predprinimatel-dolzhen-umet-rabotat-v-lyubyh-usloviyah-osnovatel-krasnoe-beloe-ob-onlain-prodazhe-alkogolya-parallelnom-importe-i-vozmozhnom-ipo'},\n",
       " {'title': 'Разработчик библиотеки для дизайнеров Freepik запустил генератор видео с моделями Runway и Luma Labs ',\n",
       "  'text': 'Он доступен платным подписчикам.',\n",
       "  'link': 'https://vc.ru/ai/1662133-razrabotchik-biblioteki-dlya-dizainerov-freepik-zapustil-generator-video-s-modelyami-runway-i-luma-labs'},\n",
       " {'title': 'Шпаргалка: Как писать промпты для Suno AI, чтобы сгенерировать действительно красивую музыку ',\n",
       "  'text': 'Я расскажу о доступных музыкальных стилях, советах по структурированию песен и о том, как написать промпт, который принесет отличные результаты.',\n",
       "  'link': 'https://vc.ru/ai/1662140-shpargalka-kak-pisat-prompty-dlya-suno-ai-chtoby-sgenerirovat-deistvitelno-krasivuyu-muzyku'},\n",
       " {'title': 'Сделали 300 карточек для фильмов онлайн-кинотеатра Иви за месяц ',\n",
       "  'text': 'Привет! Это — pinkman. Помогли стримингу оформить каталог, нужно было в сжатые сроки с нуля сделать несколько сотен уникальных обложек с ресайзами. Рассказываем, как организовали процесс и чем нам помогли нейросети.',\n",
       "  'link': 'https://vc.ru/design/1656049-sdelali-300-kartochek-dlya-filmov-onlain-kinoteatra-ivi-za-mesyac'},\n",
       " {'title': 'Как мы продали 40 франшиз за 10 месяцев: моя история масштабирования бизнеса ',\n",
       "  'text': 'Меня зовут Игорь Голиков. Я владелец франшизы химчисток «Хозяюшка». Мой бизнес начинался как небольшая сеть химчисток, и мысль о франшизе пришла не сразу. Когда я решился масштабировать бизнес, то и представить не мог, что всего за 10 месяцев к команде присоединится 40 франчайзи. В этой статье расскажу, что помогло мне найти «своих» партнеров и как…',\n",
       "  'link': 'https://vc.ru/growth/1661508-kak-my-prodali-40-franshiz-za-10-mesyacev-moya-istoriya-masshtabirovaniya-biznesa'},\n",
       " {'title': 'Apple предложила инвестировать в Индонезии $100 млн для снятия запрета на продажу iPhone 16 — Bloomberg ',\n",
       "  'text': 'В десять раз больше, чем планировала изначально.',\n",
       "  'link': 'https://vc.ru/apple/1661522-apple-indonesia'},\n",
       " {'title': 'Минюст США задумал заставить Google продать браузер Chrome — Bloomberg ',\n",
       "  'text': 'После признания компании монополистом на рынке поисковиков.',\n",
       "  'link': 'https://vc.ru/legal/1661291-minyust-ssha-zadumal-zastavit-google-prodat-brauzer-chrome-bloomberg'},\n",
       " {'title': 'Пользователи «ВКонтакте» получили возможность оставлять отзывы на бизнес-сообщества ',\n",
       "  'text': 'До этого функцию тестировали в ограниченном режиме.',\n",
       "  'link': 'https://vc.ru/retail/1661827-polzovateli-vkontakte-poluchili-vozmozhnost-ostavlyat-otzyvy-na-biznes-soobshestva'},\n",
       " {'title': 'Как использовать Midjourney для создания лучших аватаров (фотографий профиля) - я потратил всего полчаса своего времени ',\n",
       "  'text': 'Скажем прямо, в большинстве случаев Midjourney создает фотографии лучше, чем мы можем сделать сами. Прекрасные уникальные фоны, профессиональное освещение, детали одежды и композиции делают Midjourney отличной заменой традиционной или стоковой фотографии. Это также помогло мне сэкономить много денег в моей карьере в дизайнерском агентстве.',\n",
       "  'link': 'https://vc.ru/midjourney/1661823-kak-ispolzovat-midjourney-dlya-sozdaniya-luchshih-avatarov-fotografii-profilya-ya-potratil-vsego-polchasa-svoego-vremeni'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "content = get_content(result.text)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для записи результатов парсинга в файл\n",
    "def save_doc(articles, path):\n",
    "    with open(path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow(['TITLE', 'TEXT', 'LINK'])\n",
    "        for item in items:\n",
    "            writer.writerow([\n",
    "                item['title'],\n",
    "                item['text'],\n",
    "                item['link']\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обработки и запуска всех функций и определения количества страниц для парсинга:\n",
    "def parser():\n",
    "    PAGENATION =input('Сколько страниц вы хотите запарсить? ')\n",
    "    PAGENATION = int(PAGENATION.strip())\n",
    "    html = get_html(URL)\n",
    "    \n",
    "    if html.status == 200:\n",
    "        catalog = []\n",
    "        for page in range(1, PAGENATION):\n",
    "            print(f'Парсим страницу: {page}')\n",
    "            html = get_html(URL, params={'page': page})\n",
    "            catalog.extend(get_content(html.text))\n",
    "        print('PARSING ENDED')\n",
    "        print(catalog)\n",
    "        save_doc(catalog, CSV)\n",
    "    else:\n",
    "        print('ERROR !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
